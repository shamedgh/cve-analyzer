import sys
from bs4 import BeautifulSoup

sys.path.insert(0, './python-utils')

import scraper
import util

class CVEWeb():
    """
    This class can be used to extract CVE related information from the cvedetails website
    """
    def __init__(self, url, logger, cve=None):
        if ( url ):
            self.url = url
        if ( cve ):
            self.cve = cve
        self.logger = logger

    def getCve(self):
        if ( self.cve ):
            return self.cve
        else:
            #TODO
            return self.url

    def setCve(self, cve):
        self.cve = cve
        if ( not self.url ):
            self.url = ""

    def setUrl(self, url):
        self.url = url

    def extractCommitIdFromTable(self, commitTable):
        commitId = ""
        if ( commitTable ):
            allRows = commitTable.find_all("tr")
            if ( allRows ):
                allRows = allRows[1:]
                for row in allRows:
                    if ( str(row.find("th")).strip() == "<th>commit</th>" ):
                        td = row.find("td")
                        if ( td ):
                            print (str(td))
                            tdA = td.find("a")
                            if ( tdA ):
                                commitId = str(tdA.text)
                                break
                            else:
                                self.logger.error("Problem extracting commit ID from webpage")
                        else:
                            self.logger.error("Problem extracting commit ID from webpage")
                    else:
                        self.logger.error("Problem extracting commit ID from webpage")
            else:
                self.logger.error("Problem extracting commit ID from webpage")
        else:
            self.logger.error("Problem extracting commit ID from webpage")

        return commitId

    def extractCommitFileLines(self, commitDiffTable):
        #TODO
        fileLineDict = dict()
        
        #extract file names:
        if ( commitDiffTable ):
            commitDiffTableDivs = commitDiffTable.find_all("div")
            fileName = ""
            for div in commitDiffTableDivs:
                #self.logger.debug("div: %s", str(div))
                fileLine = ""
                divClass = div.get("class", "")
                #self.logger.debug("divClass: %s", str(divClass))
                if ( str(divClass).strip() == "['head']" ):
                    fileName = div.find("a").text
                    #self.logger.debug("fileName: %s", fileName)
                elif ( str(divClass).strip() == "['hunk']" ):
                    fileLine = div.text
                    #@@ -608,7 +608,7 @@ static void rds_tcp_kill_sock(struct net *net)
                    if ( fileLine.startswith("@@") ):
                        fileLine = fileLine.split("@@")[1]
                        ## -608,7 +608,7
                        fileLine = fileLine.split()[1]
                        ## +608,7
                        fileLine = fileLine.split(",")[0]
                        ## +608
                        fileLine = fileLine.replace("+", "").strip()
                        ##608
                    #self.logger.debug("fileLine: %s", fileLine)
                if ( fileName != "" and fileLine != ""):
                    fileSet = fileLineDict.get(fileName, set())
                    fileSet.add(int(fileLine))
                    fileLineDict[fileName] = fileSet
        else:
            self.logger.warning("Trying to extract commit file and lines from commit diff table which is None")

        return fileLineDict

    def getGithubCommits(self):
        filterList = ["github.com"]
        scraperObj = scraper.Scraper(self.url, self.logger)
        soupObj = scraperObj.loadWebsite()
        if ( soupObj ):
            commitLinks = util.htmlParseExtractLinks(soupObj, filterList)
        #TODO

    def getKernelGitCommits(self):
        filterList = ["git.kernel.org"]
        commitFileDict = dict()
        scraperObj = scraper.Scraper(self.url, self.logger)
        soupObj = scraperObj.loadWebsite()
        if ( soupObj ):
            commitTable = util.htmlParseExtractFirstTagWithAttr(soupObj, "table", {"class":"commit-info"})
            commitId = self.extractCommitIdFromTable(commitTable)
            commitDiffTable = util.htmlParseExtractFirstTagWithAttr(soupObj, "table", {"summary":"diff", "class":"diff"})
            if ( commitDiffTable ):
                fileLineDict = self.extractCommitFileLines(commitDiffTable)
                commitFileDict[commitId] = fileLineDict
                self.logger.debug("fileLineDict: %s", str(fileLineDict))
            else:
                self.logger.warning("getKernelGitCommits page: %s doesn't have commit diff table", self.url)
            self.logger.debug("commitId: %s", commitId)
        return commitFileDict
